#+TITLE: SQLite
* SQLite
** Android API

#+BEGIN_EXAMPLE

                                                   +----------------+
                                                   | SQLiteDatabase |                         +------------------+
                                                   +-+----------+---+                  +----->+ SQLiteConnection-+-<---+
                                                     |          |                      |      +------------------+     |
                                                     |          v                      |      +------------------+     |
                       +--------------------+--------+     +----+------------------+   +----->+ SQLiteConnection |     |
                       |                    |              | SQLiteConnection Pool-+---+      +-----+-----+------+     |
                       v thread_1           v thread_2     +-------+---------------+                |     ^            |
                  +----+----------+    +----+----------+           ^                                |     |            |
                  | SQLiteSession |    | SQLiteSession-+-----------+      +----------------------+  |     |            |
                  +----+-------+--+    +------+--+-----+           |      |PreparedStatementCache+<-+     |            |
                       |       |              |                    |      +----------------------+        |            |
                       |       +--------------+--------------------+                                      |            |
                       |                      |                                                           |            |
                       |                      +-----------------------------------------------------------+            |
                       |                                                                                               |
                       +-----------------------------------------------------------------------------------------------+
#+END_EXAMPLE

*** SQLiteDatabase & SQLiteDatabase (c)
**** addCustomFunction
*** SQLiteStatement (c)
Note that `SQLiteStatement' has nothing to do with the native
`prepared statement', it nothing but a `helper class' to store:
- sql string
- bind args
- db connection (session)

In fact, there is ONE class named `PreparedStatement', defined in the
`SQLiteConnection', which corresponds to the `native prepared
statement', and also there is `PreparedStatementCache' in
SQLiteConnection to avoid redundant statement preparations. So, cache
`SQLiteStatement' manually may make no sense? so I really doubt that
`android providers should use DatabaseUtils.InsertHelper to cache
SQLiteStatement', as mentioned in:

[[http://www.outofwhatbox.com/blog/2010/12/android-using-databaseutils-inserthelper-for-faster-insertions-into-sqlite-database/#comment-2685][android-using-databaseutils-inserthelper-for-faster-insertions-into-sqlite-database/]]

*** SQLiteSession
*** SQLiteConnection & SQLiteConnectionPool
**** Yield
**** WAL (Write-ahead Logging)
http://sqlite.org/wal.html
*** SQLiteProgram & SQLiteQuery & SQLiteQueryBuilder
*** Cursor & CursorWindow
**** SQLiteCursorDriver
**** CursorFactory
**** Cursor
***** Cursor Class Hierarchy

#+BEGIN_EXAMPLE
                                    -+----------+
                                     | Cursor/I |
                                    -+----+-----+
                                          |
                                          |
                               -+---------+-----------+
                                | CrossProcessCursor/I|
                               -+----+----+-----------+
                                          |
                                          |
                                -+-----+--+---------+
                                 | AbstractCursor/A |
                                -+--------+---------+
                                          |
                      -+------------------+---------------+----------------------+
                       |                                  |                      |
          -+-----------+--------------+          -+-------+------+       -+------+------+
           | AbstractWindowedCursor/A |           | MatrixCursor |        | MergeCursor |
          -+-----------+--------------+          -+--------------+       -+-------------+
                       |
                      -+----------------------------+
                       |                            |
              -+-------+------+      -+-------------+-------------+
               | SqliteCursor |       | BulkCursorToCursorAdaptor |
              -+--------------+      -+---------------------------+
#+END_EXAMPLE
****** Cursor across process

When Cursor in the remote process need to be returned to local process, the
remote Cursor will be wrapped into a binder object named
`CursorToBulkCursorAdaptor`, which is not a cursor, but implements methods like
`onMove`, `getWindow`, etc.

When the local process received the `CursorToBulkCursorAdaptor` binder, it
again will be wrapped into a local cursor object named
`BulkCursorToCursorAdaptor`, which is a `AbstractWindowedCursor`


#+BEGIN_EXAMPLE
               -+------------------------+
                | AbstractWindowedCursor |
               -+----------+-------------+
                           |
                           |
             -+------------+--------------+
              | BulkCursorToCursorAdaptor |
             -+------------+--------------+
                           |
                           |
                  -+-------+------+        local process (e.g. app)
   --------------- |  BulkCursor  | -------------------
                  -+-------+------+        remote process (e.g. provider)
                           |
                           |
             -+------------+--------------+
              | CursorToBulkCursorAdaptor |
             -+------------+--------------+
                           |
                           |
                    -+----------+
                     |  Cursor  |
                    -+----------+
#+END_EXAMPLE

***** Code Snippet
****** moveToFirst
#+BEGIN_SRC text
  AbstractCursor.moveToFirst
    AbstractCursor.moveToPosition(0)
      ret=SqliteCursor.onMove(origPos,0)
        if mWindow==null || newPosition < mWindow.getStartPosition()
           || newPosition >= mWindow.getStartPosition()+ mWindow.getNumRows():
           SqliteCursor.fillWindow(newPosition)
             mWindow.setStartPosition(newPosition)
             getQuery().fillWindow(newPosition)
               SQLiteQuery.nativeFillWindow(nHandle, nStatement, window.mWindowPtr,
                          startPos, mOffsetIndex);
                 // Bind the offset parameter, telling the program which row to start with
                 sqlite3_bind_int(statement, offsetParam, startPos);
                 while (!windowFull):
                   sqlite3_step(statement);
                   window->allocRow();
                   for (int i = 0; i < numColumns; i++):
                     int type = sqlite3_column_type(statement, i);
                     if (type == SQLITE_TEXT):
                       const char* text = reinterpret_cast<const char*>(sqlite3_column_text(statement, i));
                       window->putString(addedRows, i, text, sizeIncludingNull);
                     elif: // other type
                   // end for
                 // end while
                 sqlite3_reset(statement);
      if ret:
        mPos=newPos;
#+END_SRC
****** getString
#+BEGIN_SRC text
  Cursor.getString(pos)
    AbstractWindowedCursor.getString(pos)
      mWindow.getString(pos)
        nativeGetString(pos)
#+END_SRC
***** SQLiteCursor
- SQLiteCursorDriver
  used to create the SqliteCursor
- SQLiteQuery
  used to invoke `nativefillWindow`
***** To summarize
1. Cursor by itself is not `CrossProcess`, but with the help of `BulkCursor`
   ,`BulkCursorToCursorAdaptor` and `CursorToBulkCursorAdaptor`, Cursor can be
   `CrossProcess`
2. The most important methods of the `Cursor` object:
   1) fillWindow

      `nativefillWindow` will execute the real query, and fill the result set to
      the `CursorWindow`.  ps. `getCount` will invoke `fillWindow` implicitly.

   2) onMove

      `fillWindow` is during `onMove`, e.g. `moveToFirst`, `moveToNext`, ...

**** CursorWindow
`CursorWindow` is parcelable, it represents a `window` of sqlite query
data. The underlying data of a Java CursorWindow object is managed by
CursorWindow c++ object, in both of the server side and the client
side.

***** init
#+BEGIN_SRC text
  onMove
    fillWindow
      clearOrCreateWindow
        mWindow = new CursorWindow(name);
          // sCursorWindowSize specifies the window size in kb, e.g. 2048 Kb
          mWindowPtr = CursorWindow.nativeCreate(name, sCursorWindowSize);
#+END_SRC

***** how CursorWindow is passed across process

Because `CursorWindow` is only a parcelable (not a binder), so the remote
`CursorWindow` need to be fetched by the local process again and again,
e.g. during local `onMove`

#+BEGIN_SRC text
  BulkCursorToCursorAdaptor.onMove
    if (mWindow == null
        || newPosition < mWindow.getStartPosition()
        || newPosition >= mWindow.getStartPosition() + mWindow.getNumRows()):
      setWindow(mBulkCursor.getWindow(newPosition));
        // remote process
        CursorToBulkCursorAdaptor.getWindow(newPosition)
          mCursor.moveToPosition(startPos)
          return mCursor.getWindow()
            // SQLiteCursor
            mCursor.fillWindow(position, window);
              mQuery.fillWindow(position,window);
                getSession().executeForCursorWindow();
                  SQLiteConnection.nativeExecuteForCursorWindow(start, requiredRow)
                  // native
                    while (window not full):
                      sqlite3_step(stmt);
                      copy_row(window)
                    sqlite3_reset(stmt)
                  nativeFinalizeStatement(stmt);
#+END_SRC

****** 关于 CursorWindow 的一个 bug (or feature)

每次 onMove (包括 cursor.moveToPosition 等) 都会导致底层的 statement 实
际上会重新查询 .... 所以这种设计会导致这个 bug (or feature?)

#+BEGIN_SRC java
  private void query() {
      SQLiteDatabase db = SQLiteDatabase.openDatabase("/storage/sdcard1/test.db", null,SQLiteDatabase.OPEN_READWRITE, null);
      Cursor cursor=db.query("test", new String[] {"name","count"}, null,null, null, null, "name");
      Log.e("sunway","query:get count:"+cursor.getCount());
      cursor.moveToFirst();
      Log.e("sunway","moveToFirst: data:"+cursor.getString(0));
      cursor.moveToLast();
      Log.e("sunway","moved to last");
      Log.e("sunway","insert a row");

      db.beginTransaction();
      db.execSQL("INSERT INTO test VALUES (\"aaa\",1)");
      Log.e("sunway","done");
      db.setTransactionSuccessful();
      db.endTransaction();

      cursor.moveToFirst();
      Log.e("sunway","moveToFirst again: data:"+cursor.getString(0));
      cursor.close();
  }
#+END_SRC

当原有数据足够多时 (保证 moveToLast 会调用 fillWindow 替换掉当前
window), 对同一 cursor 调用两次 moveToFirst 查询的结果不同 .... 若要避
免这个情况, 要么底层的 cursor window 足够大, 能容纳所有的内容, 要么
cursor 查询返回后不 finalized statement, 这样可以保证 read transaction
持有 shared lock, 那么其他 write transaction 会因为无法获得 exclusive
lock 而无法修改数据库.

***** CursorWindow and `ashmem'

The underlying data of a Java CursorWindow is managed by CursorWindow
c++ object, and is stored using `ashmem'

#+BEGIN_SRC c++
    status_t CursorWindow::writeToParcel(Parcel* parcel) {
        status_t status = parcel->writeString8(mName);
        if (!status) {
            status = parcel->writeDupFileDescriptor(mAshmemFd);
        }
        return status;
    }

  status_t CursorWindow::createFromParcel(Parcel* parcel, CursorWindow** outCursorWindow) {
      String8 name = parcel->readString8();

      status_t result;
      int ashmemFd = parcel->readFileDescriptor();
      // ...
  }
#+END_SRC

So, CursorWindow parceling is quite efficient using `ashmem', and
that why CursorWindow could deliver more than 1MB data using binder.

#+BEGIN_EXAMPLE

~@sunway-x230> adb shell procmem 642|grep "CursorWindow"
     0K       0K       0K       0K       0K       0K       0K       0K  /dev/ashmem/CursorWindow:
     0K       0K       0K       0K       0K       0K       0K       0K  /dev/ashmem/CursorWindow:
     4K       4K       2K       0K       0K       4K       0K       0K  /dev/ashmem/CursorWindow:
     0K       0K       0K       0K       0K       0K       0K       0K  /dev/ashmem/CursorWindow:
     4K       4K       4K       4K       0K       0K       4K       0K  /dev/ashmem/CursorWindow:

#+END_EXAMPLE

** C API
*** sqlite3_open
*** sqltie3_prepare_v2
*** sqlite3_step
*** sqlite3_reset
*** sqlite3_bind
*** sqlite3_exec
*** sqlite3_get_tables
*** sqlite3_mprintf
*** sqlite3_commit_hook
*** sqlite3_rollback_hook
*** sqlite3_busy_handler
*** sqlite3_busy_timeout
*** sqlite3_trace
*** sqlite3_finalize
在 auto-commit 模式下, sqlite3_finalize 相当于 commit 的作用:
- 释放锁
- sync 日志与数据库
*** extension api
**** user defined functions
sqlite3_create_funtion
**** user defined aggregates
**** user define collations
sqlite3_create_collation
*** sample code
#+BEGIN_SRC c
  #include <sqlite3.h>
  #include <pthread.h>

  void query(sqlite3 * db) {
      sqlite3_stmt *stmt;
      const char * tail;
      int rc=sqlite3_prepare_v2(db,"select * from test", -1, &stmt, &tail);
      if (rc!=SQLITE_OK) {
          fprintf("error prepare stmt: %s", sqlite3_errmsg(db));
          exit (1);
      }
      int count=0;
      rc=sqlite3_step(stmt);
      while (rc==SQLITE_ROW) {
          count++;
          rc=sqlite3_step(stmt);
      }
      sqlite3_finalize(stmt);
      printf("query returns %d\n",count);
  }

  void * fun(void * args) {
      query((sqlite3 *)args);
  }


  int main(int argc, char *argv[]) {
      sqlite3_config(SQLITE_CONFIG_SERIALIZED);
      /* sqlite3_enable_shared_cache(SQLITE_OPEN_SHAREDCACHE); */
      sqlite3 *db;
      sqlite3 *db2;

      int rc=sqlite3_open_v2("/home/sunway/test.db", &db, SQLITE_OPEN_READWRITE, 0);

      if (rc) {
          printf("can't open db: %s",sqlite3_errmsg(db));
          sqlite3_close(db);
          exit(1);
      }

      pthread_t tid;
      pthread_create(&tid, NULL, fun, db);

      query(db);
      pthread_join(tid, NULL);
      /* char * sql="insert into test values (\"test\",1)"; */
      /* char * zerr; */
      /* rc=sqlite3_exec(db,sql,0,0,&zerr); */
      /* if (rc!=SQLITE_OK) { */
      /*  printf("error when insert: %s", zerr); */
      /*  exit (1); */
      /* } */
      return 0;
  }

#+END_SRC
** SQLite
*** sqlite3_analyzer
*** sqlite command
**** .output
**** .mode
list|column|insert|line|tabs|tcl|csv
**** .dump
**** .read
**** .tables
**** .separator
**** .schema
**** .headers [on|off]
**** explain query plan
see also [[http://www.sqlite.org/queryplanner.html][queryplanner]]
#+BEGIN_SRC sql
explain query plan select * from foo;
#+END_SRC
**** explain
#+BEGIN_SRC sql
explain select * from foo;
#+END_SRC
**** vacuum
*** sqlite SQL
**** attach database
attach database "foo.db" as db2;
select * from db2.tbl_1;
detach database db2;
**** create table
***** storage class
使用 select typeof (xx) 来查看 storage class

- integer
61
- real
61.0
- text
"a"
- blob
x'61'

***** constrains
****** column-level constrains
- not null
- unique
- primary key
- foreign key
- check
#+BEGIN_SRC sql
  create temp table foo(
  x integer,
  y integer check (y>x),
  z integer check (z>abs(y)),
  );
#+END_SRC
see also `trigger`
- collate
  - binary
  - nocase
- default
- autoincrement
****** table-level constrains
- primary key
#+BEGIN_SRC sql
  CREATE TABLE xxx (
  data1 text,
  data2 text,
  primary key (data1, data2)
  );
#+END_SRC
- unique
#+BEGIN_SRC sql
  CREATE TABLE xxx (
  _id integer primary key,
  data1 text,
  data2 text,
  unique (data1, data2)
  );
#+END_SRC
- check
**** trigger
#+BEGIN_SRC sql
  create [temp|temporary] trigger name
  [before|after|instead of] [insert|delete|update|update of columns] on table
  [for each row] [when expr]
  begin
  action
  end;
#+END_SRC
- using trigger to update view
#+BEGIN_SRC sql
  create trigger on_update_foods_view
  instead of update on foods_view
  for each row
  begin
     update foods set name=new.fname where id=new.fid;
     update food_types set name=new.tname where id=new.tid;
  end;
#+END_SRC
注: sqlite 的 trigger 不支持 `for each statement`, 只支持 `for each row`
**** transaction
- begin [ deferred | immediate | exclusive ] [transaction] 
- commit
- rollback
- savepoint
#+BEGIN_SRC sql
  begin transaction;
  insert into xxx;
  ...
  savepoint test
  ...
  rollback to test
  ...
  commit
#+END_SRC
  insert into xxx;
  save
**** confict resolution
- replace
- ignore
  忽略本次错误, 继续执行
- fail
  结束, 但不回滚
- abort
  default
  回滚, 然后结束
- rollback
  回滚, 但不结束

confict resolution can be specified in
- table or view defination
#+BEGIN_SRC sql
create temp table cast(name text unique on conflict rollback);
#+END_SRC
- in `insert`, `update`
#+BEGIN_SRC sql
insert or replace into table values (xxx);
#+END_SRC
- trigger
**** join
- inner join
join
- left outer join
left out join
- right outer join
not supported
- full outer join
not supported
- cross
select from tbl1, tbl2
**** index
refers [[explain query plan]] to delete whether index is used for optimization

- index
- unique index
- covering index
  covering index 是指同一个 index 中有多个字段, 查找时直接从 index 中
  取得了数据, 而不是从 index 取得主键, 再到主表获取数据. 例如:

  create index m3_index on foo(x,y);
  explain query plan select y from foo where x="a";

0|0|0|SEARCH TABLE foo USING COVERING INDEX m3_index (x=?) (~10 rows)

Note:
- collate 会影响 index, 例如若 select 时或建表时使用的 collate 与建立
  index 时指定的 collate 不一致时, index 无法起作用.
- create index 可以指定多个字段 (以利于形成 covering index), 但多个字
  段是联合在一起索引的, 例如 (x,y,z), 则使用 x, x and y, x and y and
  z 时索引起作用, 但使用 y and z, z 时不起作用.

**** view
- using trigger to update view
**** insert
**** update
**** select

#+BEGIN_EXAMPLE

          -+-------------------------------------------------------------------------------------+
           |       -+-----------------------------------------------------------+                |        result
           |        |                        -+---------------+                 |                |          ^
           |        |                         |               |                 |                |          |
SELECT DISTINCT heading FROM tables WHERE predicate GROUP BY columns HAVING predicate ORDER BY columns LIMIT init,int;
           | 6      | 5         | 1           | 2             | 3               | 4              | 7        | 8
           |        |           |             |               |                 |                |          |
          -+--------+          -+-------------+              -+-----------------+               -+----------+

#+END_EXAMPLE
***** distinct
distinct 可以同时修饰多个字段
#+BEGIN_SRC sql
select distinct id, name from xxx;
#+END_SRC
表示只有 (id,name) 都相同时才算相同
***** where
***** group by
***** having
***** order by
***** limit
***** sub-query
- for `select`
#+BEGIN_SRC sql
  select _id, (select name from xx where _id=f._id ) from xx as f;
#+END_SRC
- for `from`
#+BEGIN_SRC sql
  select _id from (select _id,name from xxx);
#+END_SRC
- for `order by`
#+BEGIN_SRC sql
  select _id from xxx as f order by (select score from xxx where _id=f._id);
#+END_SRC
- for `where'
#+BEGIN_SRC sql
select _id from xxx where _id in (select _id from xxx);
#+END_SRC

Note:
- sub-query 几乎可以用在任何地方
- sub-query 通常需要设置别名
- sub-query 只能返回一列.
- sub-query 有时需要返回一行 (例如在 order by 的场合), 这时若返回多行,
  则系统只会使用第一行.
***** compound query
compound query 要求各个查询返回相同的例, 且只能在 compound query 最后
有一个 order by
****** union [all]
a | b
****** intercept
a & b
****** except
a - b
***** conditional result
used to transform column values
#+BEGIN_SRC sql
  case value
    when x then value_x
    when y then value_y
    when z then value_z
    else default_value
  end
#+END_SRC
#+BEGIN_SRC sql
  select name,(select
                case
                when count(*) > 4 then 'Very High'
                when count(*) = 4 then 'High'
                when count(*) in (2,3) then 'Moderate'
                else 'Low'
                end
                from foods_episodes
                where food_id=f.id) as frequency
  from foods f
  where frequency like '%High'

#+END_SRC
**** functions
***** core functions
- LAST_INSERT_ROWID()
- coalesce (x, y, z, ...)
  return the first not null value, or null

  e.g. coalesce (null, 1, 2, null) returns 1
- ifnull (x, y)
  ifnull (x, y) <==> coalesce(x, y)
- nullif (x, y)
  若 x,y 相同返回 null, 否则返回 x.
- glob
- like
- substr
- trim
- ltrim
- rtrim
- instr
- quote
- length
- lower
- upper
- abs
- max
- min
- random
- replace
- hex
- round
- date
***** aggregation function
- avg
- sum
- total
- max
- min
- count (x)
- count (*)
**** fts
**** Summary
***** cross-join != full-outer-join
例如, 若 A 表为 3 条, 其中 _id 分别为 1,2,3. B 表为 4 条, _id 分别为
5,6,7,8, 则:
- select * from A, B where A._id = B._id 返回 0 条
- select * from A full outer join B on A._id = B._id 返回 7 条 (此处为
  假设 full-outer-join 是支持的)
***** having 与 where 的区别
- haveing 发生在 group by 之后, 而 where 发生在 group by 之前;
- 可以使用 aggregation 函数
***** aggregation 函数只可以使用在 select 之后和 having 之后
***** 使用两个 left-outer-join 模拟 full-outer-join
#+BEGIN_SRC sql
  select * from A left outer join B on A._id = B._id
  UNION
  select * from B left outer join A on A._id = B._id
#+END_SRC
***** distinct 可以使用 group by 来模拟
***** compound query 只允许在最后使用一个 order-by, 不过可以用 sub-query 来跳过这一限制
***** sub-query 几乎可以使用在任何地方, 不过只允许返回一列, 但可以返回多行 (虽然有时只有第一行有效)
***** sqlite 允许在有 group by 中查询中 select group-by 之外的字段, 只是结果是不可靠的. 例如:

#+BEGIN_SRC sql
select name, id from xxx group by id;
#+END_SRC

同理适用于 aggregation functions, 例如:

#+BEGIN_SRC sql
select *, count(*) from xxx;
#+END_SRC

***** integer primary key => autoincrement (but with filling-gaps)
***** autoincrement 会导致后续的值一定比之前的大 (不会有 filling-gaps 效果), 当到达最大值后, 返回 data is full error
这一点需要与 integer primary key 区别
***** autoincrement 必须在 integer primary key 后使用
***** storage class vs. sort
storage class 与列的定义无关, 它取决了输入的数据的格式:
61, 61,0, "a", x'61', null 的 storage class 分别为 integer, real,
text, blob, null

不同的 storage class 的排序规则:
null < integer = real < text < blob

see also [[type affinity]]
***** sqlite 的 view 是不可修改的, 但可以用 trigger 来模拟实现可修改的 view
***** index 可以同时指定多个字段, 以便使用 covering index, 但要注意查询条件, 例如
(x,y,z)三个字段的索引,使用 x, x and y, x and y and z 会使用索引, 但
y, y and z, z 不会.
***** 一次查询可能会使用多个索引, 例如使用 or 的情况下:
create index m1_index on foo(x);
create index m1_index on foo(y);
select x from foo where x="a" or y="a";
0|0|0|SEARCH TABLE foo USING INDEX m1_index (x=?) (~10 rows)
0|0|0|SEARCH TABLE foo USING INDEX m2_index (y=?) (~10 rows)
***** unique index
***** 有些情况下 index 无法使用, 例如
- glob "a*"
- like (测试了下似乎 sqlite 并不会对 like 进行优化, 可能和版本有关?)
- 多列索引时有些情况
- select xx from xx where length(x)=5, 等
***** savepoint & rollback to
***** conflict resolution
***** attach database
*** sqlite limitation
- right and full outer join
- complete ALTER TABLE support
- completing TRIGGER support
- writing to VIEWs
- GRAND and REVOKE
*** sqlite pragma
**** auto_vacuum = 0/1
**** cache_size
cache_size 表示 writer 在真正 flush 日志文件和 page cache 之前, 最多
能 cache 多少修改.

**** default_cache_size
**** case_sensitive_like = 0/1
**** count_change = 0/1
**** encoding = "UTF-8"
**** page_size = bytes
**** synchronous = FULL/NORMAL/OFF
synchronous 表示 write 在 commit 或 cache 满后如何 flush 日志文件.

特别的,在 WAL 模式下, synchronous 为 NORMAL 时 commit 也不再写数据库,
只有checkout 时才刷新.
**** vdbe_trace=ON/OFF
*** optimization
**** 使用索引
**** 避免 transient table (subquery)
许多 sqlite 操作例如 order by, aggregation, subquery 等需要使用到
transient table 来暂存中间结果, 尤其是 subquery. 这些 transient table主
要的问题是无法使用 index.
- 使用显式的 temp table 并使用索引?
**** automatic index
**** view 与 subquery 类似, 无法使用索引
**** join 的顺序
**** 使用 limit
*** references
[[http://www.sqlite.org/syntaxdiagrams.html][Syntax Diagrams For SQLite]]
** Inside SQLite
*** vdbe
*** btree (SQLite 文件格式)
**** page
SQLite 文件被分割为 page_size 大小的连续的 page (一般 page_size 为 1K, 在
建立数据库时通过 pragma 可以修改, 这个值被保存在 sqlite 文件头中)

page 1 是第一个 page, 这个 page 的格式与其他 page 都不同, 因为它的前
100 bytes 用来保存 sqlite 文件头.

sqlite 文件头中保存的信息主要有:
- magic number
- page size
- file change counter 每次对 sqlite 数据库的修改都会把这个值加1
- free page list

除去这 100 bytes, page 1 与其他 table interior page 格式相同

一共有以下几种 page:

1. table interior page
2. table leaf page
3. index interior page
4. index leaf page
5. trunk page
6. free page
7. lock byte page
8. pointer map page

前 4 种 page 因为是保存 table 和 index 内容的, 它们有类似的内部结构, 后
4 种 page 不保存数据, 所以它们的结构是单独定义的.

**** 前四种 page 的结构
page 结构包含 page 头和 cell content

page 头包含以下信息:
1. page type, 例如 0x0d 表示 table leaf page, 0x02 表示 index interior
   page 等. 不同的 page 的 cell content 格式略有不同.
2. cell content 中 cell 的个数 N
3. 第一个 cell 在 page 中的偏移量
4. cell pointer array, 这里连续的保存着 N 个偏移量, 对比 N 个 cell 的
   起始地址.
5. 第一个 free cell 的偏移量
6. 最后一个儿子 page 的 page 号 (只有 interior page 有)

从 cell pointer array 可以找到各个 cell 在当前 page 的偏移量. 每个
cell 对应于一条记录 (表记录或索引记录). cell 的格式根据 page 类型不同
略有差别.

***** table interior page
table interior page 是用来保存 sqlite 表数据的 B+-tree 中间节点. 其
cell 的格式为:

[子 page 索引] [记录号]

其中第一个字段是 page 号, 第二个字段是记录号, 所谓记录号, 就是 sqlite
表中对应于每条记录的唯一标识 (rowid)

因为 table interior page 是 B+-tree 中间节点, 所以它们只保存着索引信息
(记录号和子节点 page 号),不包含 cell 对应的记录的详细信息.

另外, sqlite 的 B-tree 或 B+-tree 并不是严格的 x 阶 B 树, 因为它每个节
点可以包含的子节点个数是不定的, 由 cell 的大小决定, 例如, table
interior page 中每个 cell 可能只占几个字节, 1K 的 page 除去 page 头和其
它一些开销可能可以保存上百个 cell.

***** table leaf page

table leaf page 是用来保存表数据的 B+-tree 叶节点, 其 cell 格式为:
[cell payload 大小][记录号][payload 内容][overflow page 索引]

其中 payload 内容 保存着一个 record 的实际的数据. 若一个 record 的内容
过多, 则会分配一个 overflow page 来保存过多的内容. 但要注意的是并不是
record 大小超过  page_size 时才使用 overflow page, 实际上, sqlite 定义
了一个常量, 使得 record 大小 page_size 的 1/4 时就会使用 overflow
page, 并且只有 7/8 的内容会放在 overflow page 里, 剩下的 1/8 内容放在
cell payload 中.

***** index interior page

index interior page 用来保存 sqlite 索引的 B-tree 中间节点, 其 cell 格
式为:

[子 page 索引] [索引使用的 key] [索引记录本身]

这里与 table interior page 的区别主要有两点:
1. table interior page 使用记录号有标识 cell 本身的 key, 而 index
   interior page 使用的是建立索引时使用 key 字段, 例如:

   create index test_index on test(name), 则对于 test_index 的
   interior page, key 就是 name 字段的值

2. index interior page 的 cell 中还保存着 cell 本身对应索引记录本身,
   因为 index interior page 是 B-tree 中间节点. 这样设计也是由 index
   的工作原理决定的.

***** index leaf page

index leaf page 是 B-tree 叶节点, 和 table leaf page 基本相同, 只是
B-tree 中间节点不包含在 B-tree 叶节点中.

**** lock byte page

lock byte page 是非常特殊的一种 page:

1. 它的大小是固定的 512 bytes, 而不是 page size 大小
2. 对于小于 1G 的 sqlite 数据库, 并不包含这种 page, 对于大于 1G 的
   sqlite 数据库, 只包含一个, 并且固定的位于 1G bytes 的位置

lock byte page 实际是用来实现文件锁的一个区域, 这个区域被设计为
1G-1G+512 bytes 的一块区域, 因为文件锁对文件的某个区域进行锁定时并不需
要该区域一定是存在的, 所以对于小于 1G 的文件, 这个page 并不存在.

之所以这个 page 规定为 512 字节, 是为了实现 sqlite 的多阶段文件锁,
sqlite 把这个 512 字节的区域又分为 3 的区域, 其中一个字节用来支持一个
reserved lock , 一个字段用来支持一个 pending lock , 剩下的 510 的字节用
来支持多个 shared lock 和一个 exclusive lock. (注: 对于 linux, shared
lock 是对 整个510 个字节区域的 read lock, 可以有无数个, exclusive 是对
这 510 个字节区域的 right lock , 只能有一个；对于 windows, 因为它只支
持 write lock , 所以 shared lock 是对 510 个字节中的某一个字节的 write
lock, 所以最多有 510 个)

**** trunk page 与 free page
在 sqlite 文件头中有一个 free page list 的指针, 指向第一个 trunk
page.

trunk page 和 free page 是 sqlite 用来缓存那些暂时不用的 page 的. 通过
trunk page 和 free page, 构成一个简单的两级索引结构: trunk page 用来做
索引, 真正缓存的 page 只是 free page.

trunk page 与 free page 是和 vacuum 相关的. 实际上 vacuum 命令消除
free page 的方法相当简单:

insert into new_table select * from orig_table

**** page 1

page 1 是第一个 page, 一般来说它是一个 table leaf page, 除了保存着 100
bytes 的 sqlite 文件头, 还保存着 sqlite_master 表的内容, 即数据库的
schema.

sqlite_master 表中最重要的一个信息应该算是每个表和索引的 root page
number 了, 有了这个信息, 我们从某个表查询时, 才能找到对应的 root page
number 进而查询整下 B-tree.

**** 总结

sqlite 数据库由 N 个 page 组成, 但这些 page 有些构成一棵棵的 B-tree
(index page), 有的构成 B+-tree (table page), 有的构成一个链表 (trunk
page 与 free page), 有的只有孤零零一个在那儿 (lock byte page) ...

*** pager
1. pager 即 page cache, 负责所有 IO 操作, 并使用 cache 加快 IO.
2. pager 是 sqlite 实现 ACID 的核心, 除了数据库文件的IO, pager 还负责
   journal 以及 lock 相关的操作.
*** lock
sqlite 在不同的层次上定义了三种锁
**** shared cache mode lock
shared cache mode 主要应用在嵌入式系统中, 可以使同一个进程的多个
connection 共享 page cache, 以显著的降低内存和 io 的消耗. 但这需要引入
额外的锁机制, 导致多个线程同时查询时速度非常慢

shared cache mode 的比较:

|-------------------------------+----------------|
| MULTITHREAD, 三个线程同时查询 | 每个线程的 rss |
|-------------------------------+----------------|
| 未使用 shared cache mode      | 8M             |
| 使用 shared cache mode        | 3.3M           |
|-------------------------------+----------------|

**** thread lock
sqlite 内部使用两个 mutex 来实现三种不同的 thread lock 模型
- core mutex
- full mutex

http://www.sqlite.org/threadsafe.html

SQLite support three different threading modes:

- SINGLETHREAD

In this mode, all mutexes are disabled and SQLite is unsafe to use in
more than a single thread at once.

同时只能有一个线程在使用 connection (相同或不同的), 否则出现段错误.

- MULTITHREAD

In this mode, SQLite can be safely used by multiple threads provided
that no single database connection is used simultaneously in two or
more threads.

同时可以有多个线程使用 connection (不同的), 否则段错误.

- SERIALIZED

In serialized mode, SQLite can be safely used by multiple threads with
no restriction.

The threading mode can be selected at compile-time (when the SQLite
library is being compiled from source code) or at start-time (when the
application that intends to use SQLite is initializing) or at run-time
(when a new SQLite database connection is being created). Generally
speaking, run-time overrides start-time and start-time overrides
compile-time. Except, single-thread mode cannot be overridden once
selected.

The default mode is serialized.

在 android 4.0 上, 该配置在编译时设为 SERIALIZED, 在 android 4.1 变为 MULTITHREAD

同时可以有多个线程使用 connection (相同或不同的)

***** Benchmark
查询 1600 W 条记录所耗的时间的比较

|---------------------------------------------------------------+------+------+-----|
| 查询类型                                                      | real | user | sys |
|---------------------------------------------------------------+------+------+-----|
| 使用 SINGLETHREAD 查询一次                                    |  3.5 |  3.5 | 0.4 |
| 使用 MULTITHREAD 查询一次                                     |  3.5 |  3.5 | 0.4 |
| 使用 SERIALZIED 查询一次                                      |  3.8 |  3.8 | 0.4 |
| 使用 MULTITHREAD 在两个线程使用不同的 connection 查询         |  7.3 |    4 | 0.4 |
| 使用 SERIALZIED 在两个线程使用不同的 connection 查询          |  7.8 |  4.2 | 0.4 |
| 使用 SERIALZIED 在两个线程使用相同的 connection 查询          |   27 |   28 |   9 |
| 使用 SHARED CACHE MODE 在两个线程中使用不同的 connection 查询 |   31 |   31 |  11 |
|---------------------------------------------------------------+------+------+-----|

可见,

- 不使用多线程的情况下, SINGLETHREAD 和 MULTITHREAD 差不多,SERIALZIED
  变慢
- 使用多线程的情况下,
  - SINGLETHREAD 无法使用
  - MULTITHREAD 可以利用多线程显著的降低 real time
  - SERIALZIED 使用不同的线程时也比 MULTITHREAD 稍慢
  - SERIALZIED 使用相同的线程时速度无法接受

综上, 使用 MULTITHREAD 多线程使用不同的 connection 是最好的选择.

***** Compile-time selection of threading mode

Use the SQLITE_THREADSAFE compile-time parameter to selected the
threading mode. If no SQLITE_THREADSAFE compile-time parameter is
present, then serialized mode is used. This can be made explicit with
-DSQLITE_THREADSAFE=1. With -DSQLITE_THREADSAFE=0 the threading mode
is single-thread. With -DSQLITE_THREADSAFE=2 the threading mode is
multi-thread.

The return value of the sqlite3_threadsafe() interface is determined
by the compile-time threading mode selection. If single-thread mode is
selected at compile-time, then sqlite3_threadsafe() returns false. If
either the multi-thread or serialized modes are selected, then
sqlite3_threadsafe() returns true. The sqlite3_threadsafe() interface
predates the multi-thread mode and start-time and run-time mode
selection and so is unable to distinguish between multi-thread and
serialized mode nor is it able to report start-time or run-time mode
changes.

If single-thread mode is selected at compile-time, then critical
mutexing logic is omitted from the build and it is impossible to
enable either multi-thread or serialized modes at start-time or
run-time.

***** Start-time selection of threading mode

Assuming that the compile-time threading mode is not single-thread,
then the threading mode can be changed during initialization using the
sqlite3_config() interface. The SQLITE_CONFIG_SINGLETHREAD verb puts
SQLite into single-thread mode, the SQLITE_CONFIG_MULTITHREAD verb
sets multi-thread mode, and the SQLITE_CONFIG_SERIALIZED verb sets
serialized mode.

***** Run-time selection of threading mode

If single-thread mode has not been selected at compile-time or
start-time, then individual database connections can be created as
either multi-thread or serialized. It is not possible to downgrade an
individual database connection to single-thread mode. Nor is it
possible to escalate an individual database connection if the
compile-time or start-time mode is single-thread.

The threading mode for an individual database connection is determined
by flags given as the third argument to sqlite3_open_v2(). The
SQLITE_OPEN_NOMUTEX flag causes the database connection to be in the
multi-thread mode and the SQLITE_OPEN_FULLMUTEX flag causes the
connection to be in serialized mode. If neither flag is specified or
if sqlite3_open() or sqlite3_open16() are used instead of
sqlite3_open_v2(), then the default mode determined by the
compile-time and start-time settings is used.

**** db file lock
***** lock

这里的 lock 是指数据库级别的文件锁, 这个锁是一个建议性锁 (advisory
lock), 实际上, 为了实现这种多状态的锁, sqlite 针对 sqlite db 文件的三块
区域(从 PENDING_BYTE 开始的 1+1+510=512 个字节)定义了三个读写锁, 通过对
不同的区域的锁定实现不同的状态.

PENDING_BYTE 目前定义为 0x40000000 (1G) 处, 需要注意的是 fcntl 对文件区
域加锁时并不需要文件真的有那么大, 所以即时一个很小不到 1G 的数据库文件,也
可以对 1G 处的"内容"进行锁定 ... 之所以设置 PENDING_BYTE 为 1G, 就是因
为当数据库文件小于 1G 时可以节省这 512 字节, 因为 windows 只支持强制性
文件锁, 为了避免 sqlite 读写这 512 字节的内容时因为强制锁出错, sqlite
要求这 512 字节的空间不允许存储任何数据.

当数据库文件大于 1G 时, 这 512 的字节被称为 lock-byte page.

#+BEGIN_EXAMPLE
                                           r
                              -+------------------------------------+
                               |                exclusive           |
                               |          -+------------------------+--------+
              -+---+   w    -+-+-+   w     | -+---+---+---+---+---+-v-+----+ |
               |  -+-------->+  -+-------->+  +   |   |   |   |   |   |    | |
              -+-+-+        -+---+         | -+---+---+---+---+---+-+-+----+ |
             rese|rved       pending       |          shared        |        |
                 ^         (starting)     -+------------------------+--------+
                -+--------------------------------------------------+
#+END_EXAMPLE                          w

- pending
- unlocked
- shared
执行任何语句前要进行 shared 状态
- reserved
  执行任何写语句前需要首先进入 reserved 状态

  shared 想升级为 reserved, 必须保证当前没有任何 reserved 及 exclusive lock
- exclusive
  - pending

    commit 前需要进行 pending 状态

    reserved 升级为 exclusive 时会先暂时的升级为 pending, pending lock 会禁止任
    何新的 lock 的获取, 包括 shared, 否则可以会因为不停的有新的 shared lock 进入
    而导致 reserved 永远无法升级为 exclusive.

  reserved要想升级为 exclusive, 必须保证当前没有任何其他的 lock, 包含 shared
***** dead lock example

|------------------------------------------+-------------------------------------------|
| A connection                             | B connection                              |
|------------------------------------------+-------------------------------------------|
| BEGIN;                                   |                                           |
|                                          | BEGIN;                                    |
|                                          | # acquiring `reserved` lock ok            |
|                                          | INSERT INTO foo values("bar")             |
| # acquiring `shared` lock ok             |                                           |
| SELECT * from foo                        |                                           |
|                                          | # acquiring `exclusive` lock failed[fn:1] |
|                                          | COMMIT;                                   |
|                                          | SQL error: database is locked             |
| # acquiring `reserved` lock failed[fn:2] |                                           |
| INSERT INTO foo values ("bar")           |                                           |
| SQL error: database is locked            |                                           |
|------------------------------------------+-------------------------------------------|

android framework 中采用了 ONE primary connection + N non-primary
connections 的 connection pool 方案, 可能也是考虑到了这种死锁:

primary connection 用于"可能"需要写操作的 transaction, 只有一个. 而
non-primary connection 是用于读操作的 transaction, 可以有 N 个. 但这种
做法仍然无法避免多个进程同时对同一个数据库写时的死锁, 如果要避免,可能需
要要求所有写操作的 transaction 都以 begin reversed 开始.

***** transaction
- begin [deferred]
- begin immediate
- begin exclusive
**** FAQ
***** Can multiple applications or multiple instances of the same application access a single database file at the same time?
http://www.sqlite.org/faq.html#q5

Multiple processes can have the same database open at the same
time. Multiple processes can be doing a SELECT at the same time. But
only one process can be making changes to the database at any moment
in time, however.

SQLite uses reader/writer locks to control access to the
database. (Under Win95/98/ME which lacks support for reader/writer
locks, a probabilistic simulation is used instead.) But use caution:
this locking mechanism might not work correctly if the database file
is kept on an NFS filesystem. This is because fcntl() file locking is
broken on many NFS implementations. You should avoid putting SQLite
database files on NFS if multiple processes might try to access the
file at the same time. On Windows, Microsoft's documentation says that
locking may not work under FAT filesystems if you are not running the
Share.exe daemon. People who have a lot of experience with Windows
tell me that file locking of network files is very buggy and is not
dependable. If what they say is true, sharing an SQLite database
between two or more Windows machines might cause unexpected problems.

We are aware of no other embedded SQL database engine that supports as
much concurrency as SQLite. SQLite allows multiple processes to have
the database file open at once, and for multiple processes to read the
database at once. When any process wants to write, it must lock the
entire database file for the duration of its update. But that normally
only takes a few milliseconds. Other processes just wait on the writer
to finish then continue about their business. Other embedded SQL
database engines typically only allow a single process to connect to
the database at once.

However, client/server database engines (such as PostgreSQL, MySQL, or
Oracle) usually support a higher level of concurrency and allow
multiple processes to be writing to the same database at the same
time. This is possible in a client/server database because there is
always a single well-controlled server process available to coordinate
access. If your application has a need for a lot of concurrency, then
you should consider using a client/server database. But experience
suggests that most applications need much less concurrency than their
designers imagine.

When SQLite tries to access a file that is locked by another process,
the default behavior is to return SQLITE_BUSY. You can adjust this
behavior from C code using the sqlite3_busy_handler() or
sqlite3_busy_timeout() API functions.

***** Is SQLite threadsafe?
http://www.sqlite.org/faq.html#q6

Threads are evil. Avoid them.

SQLite is threadsafe. We make this concession since many users choose
to ignore the advice given in the previous paragraph. But in order to
be thread-safe, SQLite must be compiled with the SQLITE_THREADSAFE
preprocessor macro set to 1. Both the Windows and Linux precompiled
binaries in the distribution are compiled this way. If you are unsure
if the SQLite library you are linking against is compiled to be
threadsafe you can call the sqlite3_threadsafe() interface to find
out.

Prior to version 3.3.1, an sqlite3 structure could only be used in the
same thread that called sqlite3_open() to create it. You could not
open a database in one thread then pass the handle off to another
thread for it to use. This was due to limitations (bugs?) in many
common threading implementations such as on RedHat9. Specifically, an
fcntl() lock created by one thread cannot be removed or modified by a
different thread on the troublesome systems. And since SQLite uses
fcntl() locks heavily for concurrency control, serious problems arose
if you start moving database connections across threads.

The restriction on moving database connections across threads was
relaxed somewhat in version 3.3.1. With that and subsequent versions,
it is safe to move a connection handle across threads as long as the
connection is not holding any fcntl() locks. You can safely assume
that no locks are being held if no transaction is pending and all
statements have been finalized.

Under Unix, you should not carry an open SQLite database across a
fork() system call into the child process. Problems will result if you
do.

*** type system

sqlite 的类型系统被称为 manifest typing (或 latent typing, dynamic
typing), 而不是其他 DBMS 采用的 static typing.

所谓 manifest typing, 是指数据的类型不是由表定义时决定的, 而是由数据本
身决定的. 通过观察 table leaf page 中 cell 的格式可以更清楚的认识这一
点: 每个 cell 对应着一条记录, cell 的格式既包含记录的数据, 也包含记录中
各个字段的类型... 显然, 相对于 static typing, sqlite 的这种类型系统会占
用更多的文件空间, 但也带来了一些灵活性. 

由数据本身决定的类型信息,称之为 storage type, sqlite 定义了以下几种
storage type:

- NULL
- INTEGER
- REAL
- TEXT
- BLOB

为了与其他 DBMS 和 sql 标准尽量兼容, sqlite 在建表中也支持指定一些类型
信息, 例如 VARCHAR, 这些类型称为 affinity type. 在读取和写入数据时,
sqlite 会根据 storage type 与 affinity type 之间的一些规则进入类型转换.

另外, storage type 也会影响一些和比较相关的操作, 如 order by, group by
等.

sqlite 定义几种 affinity type:

- INTEGER
- TEXT
- NONE
- REAL
- NUMERIC

在建表时, sqlite 使用了如下的规则来确定 affinity type:

- 若类型的名字包含 INT, 则该列的 affinity type 为 INTEGER
- 若类型名字包含 CHAR, CLOB, TEXT, 则为 TEXT
- 若类型名字包含 BLOB, 则为 NONE
- 若类型名字包含 REAL,FLOA,DOUB,则为 REAL
- 否则, 为 NUMERIC

所以, create table test (num test) 是一个合法的语句... create table
test (name CHAR) 与 create table test (name VARCHAR) 是一样的...

#+BEGIN_EXAMPLE

      storage type A            storage type B
           |                          ^
           | insert                   | query
           v                          |
-----------|--------------------------|---------
           |                          |
           |                          |
       conversion A            conversion B
           |      (affinity type)     |
          -+------storage type C------+

#+END_EXAMPLE

由上图所示, 使用 storage type 的有三个场合, 类型转换在读写数据库时都会
发生.

**** 写数据库时的类型转换

当向数据库写入数据时, 在 conversion A 进行之前, sqlite 需要确定
storage type A:

- 若数据使用引号包起来, 则为 TEXT
- 若没有包含小数点或 e指数, 则为 INTEGER
- 若包含小数点或 e, 则为 REAL
- 若为 NULL, 则为 NULL
- 若为 X"abcd"形式, 则为 BLOB

若数据是通过 sqlite3_bind_* 指定的, 则 storage type 与不同的 bind 方法
是对应的, 则 sqlite3_bind_blob 绑定的数据是 BLOB 类型. 

确定 storage type A 后, sqlite 使用 affinity type 进行 conversion A:
1. TEXT affinity type

   - BLOB, TEXT, NULL 三种 storage type 会被直接保存, 不进行转换, 则
     storage type C 是 BLOB, TEXT 和 NULL
   - INTEGER, REAL 会被转换为相应的字符串, 即 123 -> "123", 且 storage
     type C 会变为 TEXT

2. NUMERIC affinity type

   - BLOB, NULL 不会被转换
   - 其他类型会尽量被转换为 INTEGER 或 REAL

3. INTEGER affinity type

   与 NUMERIC 类似, 但是会尽量会转换为 INTEGER. 例如:
   insert into test values ("123"), 123 最终的 storage type 会是
   INTEGER 而不是 TEXT. 但 12.1 不会转换为 12, 因为会损失数据. 

4. REAL affinity type

   与 NUMERIC 类似, 但整数会被转换为浮点数.

5. NONE affinity type
   
   不做任何转换

综上所述:

1. conversion A 会将输入的数据从 storage type A 转换为 storage C, 在转
   换过程中决不会丢失数据 (例如不会把 12.1 转换为 12),

2. NONE 不做任何转换,TEXT 尽量转换为 TEXT, NUMERIC 尽量转换为 INTEGER
   或 REAL, INTEGER尽量转换为 INTEGER, REAL 尽量转换为 REAL

3. 以上所有的转换, 若失败, 则直接保存,不会发生数据无法插入的情况.

4. BLOB, NULL 永远不会被转换.

**** 读数据库时的类型转换

在读数据库时, 应用会使用 sqlite3_column_xxx 函数期望获取一个 xxx 类型的
数据 (storage type B), 当与 storage type C 不一致时, conversion B 会起
作用. 要注意的是 conversion B 并不需要 affinity type 参与, 它完全由
storage type B 和 storage type C 决定.

|----------------+----------------+---------------|
| storage type C | storage type B | conversion B  |
|----------------+----------------+---------------|
| NULL           | INTEGER        | 0             |
| NULL           | FLOAT          | 0             |
| NULL           | TEXT           | null pointer  |
| NULL           | BLOB           | null pointer  |
|----------------+----------------+---------------|
| INTEGER        | FLOAT          | float(int a)  |
| INTEGER        | TEXT           | sprintf("%d") |
| INTEGER        | BLOB           | sprintf("%d") |
|----------------+----------------+---------------|
| FLOAT          | INTEGER        | int(float a)  |
| FLOAT          | TEXT           | sprintf("%f") |
| FLOAT          | TEXT           | sprintf("%f") |
|----------------+----------------+---------------|
| TEXT           | INTEGER        | atoi          |
| TEXT           | FLOAT          | atof          |
| TEXT           | BLOB           | no change     |
|----------------+----------------+---------------|
| BLOB           | INTEGER        | atoi          |
| BLOB           | FLOAT          | atof          |
| BLOB           | TEXT           | no change     |
|----------------+----------------+---------------|

由此可见, conversion B 有可能丢失数据, 例如 int(float a) 或者
atoi("abc")

**** 处理 NULL
**** 比较不同 storage type 的大小

- 若比较的双方来自两个列, 则使用以下的规则
  null < integer, real < text < blob
- 若一方来自一列, 另一方来自输入或另一个查询或表达式的结果, 则另一个结
  果会先经过 conversion A 的转换 (使用第一方的 affinity type) 再应用第
  一条规则
- 若双方都来自输入或中间结果, 则不做转换, 直接应用第一条规则
- 以上规则不仅适用于 <, between, in 等, 也适用于 order by, group by 等

例如:
#+BEGIN_SRC sql
  create table test (name INTEGER);
  insert into test values (1);
  insert into test values ("abc");
  insert into test values ("2.1");
  insert into test values (3);
#+END_SRC
输出为:
#+BEGIN_EXAMPLE
  sqlite> select typeof(name),name from test order by name desc;
  text|abc
  integer|3
  real|2.1
  integer|1
#+END_EXAMPLE

**** 关于类型系统的总结

- 不同的 storage type C 一起排序时是分段排序的
- conversion A 不会损失数据精度, 但 conversion B 会
- conversion A 使用 affinity type 来参与转换, conversion B 不使用
- 在比较不同的 storage type C 的大小时, 可能会使用到 conversion A
** sqlite3.c
*** sqlite3_open_v2
**** sqlite3_initialize
#+BEGIN_SRC text
  sqlite3_initialize
    // 初始化 mutex 系统
    sqlite3MutexInit
      if(!sqlite3GlobalConfig.mutex.xMutexAlloc):
        // 用户可以通过 sqlite3_config(SQLITE_CONFIG_MUTEX, xxx) 指定一个自
        // 定义的 mutex 实现 ... 若没有指定, 则根据平台的不同选择一个默认
        // 的 mutex 实现
        if(sqlite3GlobalConfig.bCoreMutex):
          // 若 sqlite 的编译时选项指定了 sqlite 为 SINGLETHREAD,
          // 或者通过 sqlite3_config 指定了 SQLITE_CONFIG_SINGLETHREAD 则 bCoreMutex
          // 会为空, 这时整个 mutex 系统会不起作用: 不论是 core mutex 还是
          // 和 db->mutex 相关的 full mutex
          pFrom = sqlite3DefaultMutex();
          // sqlite3DefaultMutex 在编译时会根据平台选择合适的版本
        else:
          pFrom = sqlite3NoopMutex();
          // sqlite3NoopMutex 中所有函数都为空操作.
        memcpy(&sqlite3GlobalConfig.mutex, pFrom, offsetof(sqlite3_mutex_methods, xMutexAlloc));
  
    // 初始化 malloc 系统 
    sqlite3MallocInit();
      // 用户可以通过 sqlite_config(SQLITE_CONFIG_MALLOC,xxx)
      // 指定一个自定义的 malloc 实现
      if(sqlite3GlobalConfig.m.xMalloc==0):
          // 平台相关的默认实现
          sqlite3MemSetDefault();
  
    // 初始化各种自定义函数, 如 sum, like ..., 把这些函数通过
    // sqlite3FuncDefInsert 加入到一个全局的 hash map 中, 这些函数包括:
    // trim, min, max, typeof, length, substr, round, upper, lower,
    // hex, random, nullif, sqlite_version, sqlite_log, last_insert_rowid,
    // sum, total, avg, like, 等
    sqlite3RegisterGlobalFunctions();
  
    // 初始化 pcache
    sqlite3PcacheInitialize();
    // 用户可以通过 sqlite_config 指定一个自定义 pcache 实现
    if(sqlite3GlobalConfig.pcache2.xInit==0):
      // 设置 pcache 相关的函数为默认的函数, 如 pcache1Init,
      // pcache1Truncate, xxx
      sqlite3PCacheSetDefault();
      
    // 初始化平台相关的函数, 主要是和文件系统相关, 例如 xRead, xOpen, xDelete
    // 等, 也有少量和 vfs 无关的函数, 例如 xSleep, xCurrentTime 等
    sqlite3OsInit();
#+END_SRC

总结:

sqlite3_initialize 会初始化 malloc, mutex, pcache, 这三个子系统都是可以
通过 sqlite3_config 设置为一个用户自定义实现的. 另外还要初始化平台相关
的 vfs 实现. 因为初始化时需要修改一些全局的变量, 所以需要 mutex 子系统
必须先初始化成功. 若当前模式为 SINGLETHREAD, 则会因为 bCoreMutex 为假导
致 mutex 系统没有初始化, 进行导致上层应用无法正常在两个线程中同时打开数
据库.

**** 初始化 db
#+BEGIN_SRC text
  openDatabase
    sqlite3_initialize
    // 根据 mutex 的配置决定是否启用 db 相关的 db->mutex
    // 最终的结果是: 若 sqlite3_config 指定了 SERIALIZED
    // 或者 sqlite3_open_v2 时指定了 FULLMUTEX 选项, 则
    // db->mutex 会被启用.
    // 根据 sqlite3_config, sqlite3_open_v2 或编译选项不同
    // bCoreMutex 和 bFullMutex 会被不同的置位.
    // sqlite 内部有两种 mutex, 一种是通过
    // sqlite3MutexAlloc(SQLITE_MUTEX_STATIC_MASTER) 这种形式
    // 建立的静态的锁, 一共有五个, 对应于 sqlite 中几个不同的
    // critical area 的加锁.  另一种是通过 db->mutex 保存的和
    // 单个 db 有关的锁.
    // 若 bCoreMutex 无效, 则所有 mutex 都无效, 不能有多个线程同时执行
    // sqlite 相关的代码, 对应于 SINGLETHREAD 的情 况.
    // 若 bCoreMutex 有效, bFullMutex 无效, 则那几个静态的锁有效,
    // 表示可以有多个线程同时操作不同的 db connection, 对应于
    // MULTITHREAD .若 bCoreMutex 有效, bFullMutex 有效, 则
    // db->mutex 也是有锁保护的, 同一个 db connection 可以在不同的
    // thread 中同时使用, 对应于 SERIALIZED.
    
    if(sqlite3GlobalConfig.bCoreMutex==0):
      isThreadsafe = 0;
    else if(flags & SQLITE_OPEN_NOMUTEX):
      isThreadsafe = 0;
    else if(flags & SQLITE_OPEN_FULLMUTEX):
      isThreadsafe = 1;
    else:
      isThreadsafe = sqlite3GlobalConfig.bFullMutex;
    if(isThreadsafe):
      db->mutex = sqlite3MutexAlloc(SQLITE_MUTEX_RECURSIVE);
  
    // 设置默认的 collation
    createCollation(db, "BINARY", SQLITE_UTF8, 0, binCollFunc, 0);
    createCollation(db, "RTRIM", SQLITE_UTF8, (void*)1, binCollFunc, 0);
    createCollation(db, "NOCASE", SQLITE_UTF8, 0, nocaseCollatingFunc, 0);
  
    // 默认 collation 为 BINARY
    db->pDfltColl = sqlite3FindCollSeq(db, SQLITE_UTF8, "BINARY", 0);
  
    // 初始化 btree 模块, 打开数据库文件
    sqlite3BtreeOpen(db->pVfs, zOpen, db, &db->aDb[0].pBt, 0, flags |SQLITE_OPEN_MAIN_DB);
      // 真正打开文件
      sqlite3PagerOpen(pVfs, &pBt->pPager, zFilename, ..)
      // 读取文件头, 获得 page size 等, 注意 SHORT_READ 不算错误.
      sqlite3PagerReadFileheader(pBt->pPager,sizeof(zDbHeader),zDbHeader);
      // 设置默认的 busy handler
      sqlite3PagerSetBusyhandler(pBt->pPager, btreeInvokeBusyHandler, pBt);
      // 若上一步成功读到了文件头, 则根据文件头设置 page size
      sqlite3PagerSetPagesize(pBt->pPager, &pBt->pageSize, nReserve);
  
    // sqlite 支持通过 attach 的方法在一个 db connection 中打开多个 db.
    // 这些 db 都放在 aDb 数据中. 默认初始时有两个 db, 一个 main, 代表
    // sqlite 启动时找开的 db, 还有一个 temp 表示临时 db, 例如通过
    // create temp table 建立的表都放在 temp db 中.
    // 例如:
    // select * from main.test == select * from test;
    // create temp table test2 (name TEXT);
    // select * from temp.test2;
    db->aDb[0].zName = "main";
    db->aDb[0].safety_level = 3;
    db->aDb[1].zName = "temp";
    db->aDb[1].safety_level = 1;
  
    // 自动加载一个 extension, 参考 http://www.sqlite.org/loadext.html
    sqlite3AutoLoadExtensions(db);
  
    // 初始化一些扩展模块: fts, icu, r-tree
    sqlite3Fts1Init(db);
    sqlite3IcuInit(db);
    sqlite3RtreeInit(db);
#+END_SRC

**** 总结
sqlite3_open_v2 的过程:
1. 会初始化 malloc, mutex, pcache 等相关的回调函数, 根据平台的不同注册
   一些 vfs 相关的回调函数
2. 初始化 mutex, 注册一些 min,max, sum 等内部函数, 注册 collation 函数.
3. 然后打开 btree 和 pager 模块, 使用 pager 从文件头中读取 page size 设置到 pager.
4. 加载其他 extension, 初始化 fts, icu, r-tree 模块.

在 pager 初始化时, 会真正打开数据库文件并读取文件头, 其他的内容例如
schema 在 sqlite3_open_v2 过程中暂时不会读取: 后面第一次访问数据库时会
读取 schema (即 sqlite_master 表)
*** sqlite3_prepare
#+BEGIN_SRC text
  sqlite3LockAndPrepare
    // prepare 时需要 lock 住 db->mutex, 即 bFullMutex 模式
    // 因为只有 SERIALIZED 模式下 db->mutex 才起作用, 
    // 所以非 SERIALIZED 模式下不能在不同线程同时调用 sqlite3_prepare,
    // 否则会出错
    sqlite3_mutex_enter(db->mutex);
#+END_SRC
*** sqlite3_step
** Benchmark
分别使用c,java 程序插入10w条记录, 设置 synchronous 为 full 或 off, 保
存数据库文件到 sdcard 或 mtd 设备. java 程序使用 execSQL 或
InsertHelper.

- java 测试程序
#+BEGIN_SRC java
  private void writeDatabase() {
      // mtd test: use /data/test.db to  mtd
      // sd test: use  /storage/sdcard1/test.db
      SQLiteDatabase db = SQLiteDatabase.openDatabase("/data/test.db", null,SQLiteDatabase.OPEN_READWRITE, null);
      // synchronous = full
      // synchronous = off
      db.execSQL("pragma synchronous=full");
      long startTime=System.currentTimeMillis();
      InsertHelper helper=new InsertHelper(db, "test");
      ContentValues values=new ContentValues();
      values.put("name", "test");
      values.put("count", 3);
      int commit_time=0;
      int exec_time=0;
      for (int i = 0; i < 10; i++) {
          long time1=System.currentTimeMillis();
          db.beginTransaction();
          for (int j = 0; j < 10000; j++) {
              // execSQL test
              // db.execSQL("insert into test values (\"test\",2)");

              // InsertHelper
              helper.insert(values);
          }
          db.setTransactionSuccessful();
          long time2=System.currentTimeMillis();
          db.endTransaction();
          long time3=System.currentTimeMillis();

          exec_time+=(time2-time1);
          commit_time+=(time3-time2);
      }
      long endTime=System.currentTimeMillis();
      Log.e("sunway","done: all_time: "+(endTime-startTime)+"mss avg_exec_time: "+exec_time/10 +"ms "+" avg_commit_time: "+commit_time/10+"ms");

  }


#+END_SRC

- c 测试程序
#+BEGIN_SRC c
  #include "sqlite3.h"
  #include <pthread.h>

  void insert(sqlite3 * db) {
      char * zerr;
      int rc=0;
      rc=sqlite3_exec(db,"pragma synchronous=full;",0,0,&zerr);

      struct timeval tv;
      int begin=0;
      int end=0;
      int exec_time=0;
      int commit_time=0;

      int j=0;

      gettimeofday(&tv,NULL);
      begin=tv.tv_sec*1000+tv.tv_usec/1000;

      for (j=0; j<10; j++) {
          gettimeofday(&tv,NULL);
          int time1=tv.tv_sec*1000+tv.tv_usec/1000;

          rc=sqlite3_exec(db,"begin transaction",0,0,&zerr);
          char * sql="insert into test values (?1, ?2)";
          sqlite3_stmt *stmt;
          const char * tail;
          rc=sqlite3_prepare_v2(db, sql, strlen(sql), &stmt,&tail);
          int i=0;
          for (i = 0; i < 10000; ++i) {
              sqlite3_bind_text(stmt, 1, "test", strlen("text"), SQLITE_TRANSIENT);
              sqlite3_bind_int(stmt, 2,1);
              sqlite3_step(stmt);
              sqlite3_reset(stmt);
          }
          gettimeofday(&tv,NULL);
          int time2=tv.tv_sec*1000+tv.tv_usec/1000;

          rc=sqlite3_exec(db,"end transaction",0,0,&zerr);

          gettimeofday(&tv,NULL);
          int time3=tv.tv_sec*1000+tv.tv_usec/1000;
          sqlite3_finalize(stmt);
          exec_time+=(time2-time1);
          commit_time+=(time3-time2);
      }
      gettimeofday(&tv,NULL);
      end=tv.tv_sec*1000+tv.tv_usec/1000;

      printf("done: total_time: %d ms, avg_exec_time: %d ms, avg_commit_time: %d ms\n", end-begin, exec_time/10, commit_time/10);
  }


  int main(int argc, char *argv[]) {
      sqlite3 *db;
      sqlite3_open_v2("/data/test.db", &db, SQLITE_OPEN_READWRITE, 0);

      pthread_t tid;
      pthread_create(&tid, NULL, insert, db);
      pthread_join(tid, NULL);

      return 0;
  }

#+END_SRC

|-------------+---------+-------------------+-----------------+--------------------+----------------------|
| synchronous | storage | method            | total_time (ms) | avg_exec_time (ms) | avg_commit_time (ms) |
|-------------+---------+-------------------+-----------------+--------------------+----------------------|
| off         | sd      | c                 |            2002 |                172 |                   27 |
| off         | mtd     | c                 |            1888 |                163 |                   25 |
|-------------+---------+-------------------+-----------------+--------------------+----------------------|
| full        | sd      | c                 |            3641 |                165 |                  198 |
| full        | mtd     | c                 |            1913 |                158 |                   31 |
|-------------+---------+-------------------+-----------------+--------------------+----------------------|
| full        | ssd     | c                 |             450 |                 19 |                   25 |
|-------------+---------+-------------------+-----------------+--------------------+----------------------|
| off         | sd      | java/execSQL      |           12996 |               1269 |                   29 |
| off         | sd      | java/insertHelper |           10458 |               1029 |                   16 |
| off         | mtd     | java/insertHelper |           10067 |                977 |                   29 |
|-------------+---------+-------------------+-----------------+--------------------+----------------------|
| full        | sd      | java/execSQL      |           15385 |               1252 |                  285 |
| full        | sd      | java/insertHelper |           11874 |                987 |                  199 |
| full        | mtd     | java/insertHelper |            9948 |                963 |                   31 |
|-------------+---------+-------------------+-----------------+--------------------+----------------------|

- 总结
  - 使用 java  api 测试时, 执行 sql 语句的速度
    比 c 程序慢 7 倍左右
  - insertHelper 比普通的 execSQL 有 20% 的提升
  - java api 和 c api 在 commit 时间上没有差别
  - 在 sd 卡上, synchronous off 有近10倍的性能提长[fn:3]
  - 在 mtd 上, synchronous 似乎没有差别.

** Other
*** WAL
Write Ahead Logging (WAL) 是与 sqlite 默认的 rollback journal (或
delete journal, shadow paging) 完全不同的一种 journal mode. 通过 WAL,
数据库可以做到读和写互相完全不干扰, 并且减少 IO 操作.

**** How WAL works
当 commit 一个 write transaction 时, rollback journal 的作法是先刷新所
有修改到 journal, 然后再刷新 cache 到数据库. 而 WAL 的作法是只将修
改刷新到 wal journal 中, 而不修改数据库. 只有当用户调用 pragma
wal_checkpoint 或 超过 1000 页被修改时, wal journal 中的修改才会
被写回到数据库.

为了使 read transaction 能读到最新的数据, 每个 read transaction 开始时
会扫描 wal journal, 并在 wal file 中记下一个 mark point, 在读数据库时,
根据一个 wal index shm 判断要读的 page 是否在 wal journal 中, 若存在,
并且不超过 mark point, 则使用 wal journal 中的数据, 否则使用数据库中的
数据. 这样可以使得读写不用互相等待. (但这样有一点问题, 就是无法保证读到
最新的数据, 因为有可能在读的过程中, 又有新的数据追加到 wal journal
file 中 makr point 之后)

***** WAL 的优点

- 读写互不影响
- 降低了IO的使用

  commit 只需要写 wal journal file, 不需要写数据库. 特别的, 若 WAL 模式
  下设置 pragma synchronous 为 NORMAL 的话,则 commit 根本不会导致 IO 操
  作,只有 checkpoint 才会.  因此, 在 wal 模式下, commit 不进行 IO 可能
  会导致异常重启后数据丢失, 但不会造成数据库崩溃.

  checkpoint 进行的 IO 操作包括:
  1. 写 wal 到磁盘
  2. 写 wal 到数据库
  3. 重置 wal

***** WAL 的缺点

- 可能无法读到"最新"的数据, 因为 read transaction 无法 block write
  transaction
- 过大的 read transaction 会阻止 checkpoint (当 read transaction 正在进
  行时, 虽然允许 write transaction 追加数据到 wal journal, 但不允许清空,
  因为 read transaction 已经在journal 中标记了 mark point), 进而导致
  wal journal 过大, 从而使 read transaction 变慢

***** WAL 的配置
- pragma journal_mode=wal 开启 wal 模式
- pragma journal_mode=delete 关闭 wal 模式
- wal 模式的配置是 persistent 的
- pragma wal_autocheckpoint=1000 设置 autocheckpoint 的 thresh-hold
  特别的, 这个值越大, 则写的性能越高, 这个值越小, 则读的性能越好.

**** 关于 WAL journal file 的一个实验
#+BEGIN_SRC sql
  -- these are auto-committed
  insert into test values ("a", 1);
  insert into test values ("a", 1);
  insert into test values ("a", 1);
  -- 现在, 记录应该存在 test.db-wal 中, 但还没有写到数据库中
  -- case A: 不调用 pragma wal_checkpoint
    -- kill sqlite3_process
    -- case A1: 先删除 test.db-wal, 再打开 test.db
      select count(*) from test where name="a";
      0
    -- case A2: 不删除 test.db-wal, 找开 test.db
      select count(*) from test where name="a";
      3
  -- case B: 调用 pragma wal_checkpoint
    -- kill sqlite3_process
    -- 无论是否删除 test.db-wal, 打开 test.db
      select count(*) from test where name="a";
      3
#+END_SRC

*** FTS
FTS (Full Text Search), 即全文检索,主要有以下几个方面:

- stemming (词根)
- tokenizer &  word segregation (分词)
- inverted index (倒排索引)

**** stemming
http://en.wikipedia.org/wiki/Stemming

A stemmer for English, for example, should identify the string "cats" (and
possibly "catlike", "catty" etc.) as based on the root "cat".and "stemmer",
"stemming", "stemmed" as based on "stem".

A stemming algorithm reduces the words "fishing", "fished", "fish", and "fisher"
to the root word, "fish". On the other hand, "argue", "argued", "argues",
"arguing", and "argus" reduce to the stem "argu"

android contacts provider 就是使用的一种叫做 porter 的 stemmer 算法, 所以用 cat
可以查找到名为 catty 的人也是正常的.
**** tokenizer and word segregation (分词)
全文检索是基于`关键字`匹配的检索, 与传统的 grep 等检索方法不同, 全文检索需要先建
立索引文件, 建立索引文件的第一步就是将全文分解为一系列的关键字. 例如:

"A stemmer for English, for example, should identify the string "cats" (and
possibly "catlike", "catty" etc.) as based on the root "cat""

这句话可能会被分解为以下的关键字:

stem, english, example, identify, string, cat, possible, base, root

tokenize 的过程主要分为三步:
1. 分词, 对英文来说, 基本就是以空格来分词
2. 抛弃一些 stop words, 如 a, for, should, and ,etc, as, on 等
3. 对剩下的非 stop words 使用 stemming 算法, 例如 cats->cat, stemmer->stem

***** 分词
英文分词比较简单,就是以空格来分词, 对于中文或其他一些语言就麻烦的多, 以中文为例,
主要有以下几种分词方法:

1. N元分词
   就是简单的每N个字算一个词,
   - 1元分词:
   英/文/分/词/比/较/简/单

   - 2元交叉为例:
   英文/文分/分词/词比/比较/较简/简单

2. 基于词典匹配的分词
   - 正向最大匹配
     "市场/中国/有/企业/才能/发展"
   - 逆向最大匹配
     "市场/中/国有/企业/才能/发展"
   - 双向最大匹配
3. 基于统计的分词


从目前存在的项目看, 综合N元分词与基于词典匹配的分词是主流的方法, 以 Apache
Lucene 为例: 它包含以下几种中文分词算法:
http://blog.csdn.net/chaocy/article/details/5938741

- StandardAnalyzer & ChineseAnalyzer (一元分词)

2008/年/8/月/8/日/晚/举/世/瞩/目/的/北/京/第/二/十/九/届/奥/林/匹/克/运/动/会/开
/幕/式/在/国/家/体/育/场/隆/重/举/行

- CJKAnalyzer (交叉二元分词)

2008/年/8/月/8/日晚/举世/世瞩/瞩目/目的/的北/北京/京第/第二/二十/十九/九届/届奥/
奥林/林匹/匹克/克运/运动/动会/会开/开幕/幕式/式在/在国/国家/家体/体育/育场/场隆/
隆重/重举/举行/

- MIK_CAnalyzer  (最大匹配+二元交叉)

2008年/8月/8日/晚/举世瞩目/目的/北京/第二十九届/奥林匹克运动会/开
幕式/在国/国家/体育场/隆重举行/

- etc

sqlite3 中因为支持 FTS, 所以也支持几种分词算法:
- simple
  针对英文, 根据空格分词
- porter
  针对英文, 使用 port stemmer
- icu
  使用 icu 库进行简单分词, 没有看懂 fts_icu 的源码, 从分词结果看类似于一元分词
  (待确定)

**** inverted index (倒排索引)
通过分词算法确定关键词后, FTS 会使用倒排索引建立索引, 例如全文有两句话:

`今天天气怎么样.
今天天气不错. `

- 分词的结果

  今天/天气/怎么样/今天/天气/不错

- 倒排索引结果

  今天->1,0;2,0
  天气->1,2;2,2
  怎么样->1,4
  不错->2,4

倒排索引的结果通常会以一种高效的利于查找的形式保存到索引文件中, 例如根据关键字排
序, 或使用 B 树
**** 查找过程
根据索引文件格式的不同, 查找的过程有所区别, 以 B 树为例, 查找过程就是以查找字符
串为KEY在B树中查找该关键字,查到的VALUE就是该关键字在文档中的行列位置.

全文查找速度很快,但有一个明显的缺点: 检索的效果依赖于关键字的选择.

例如,
- 使用 "tty" 无法检索到 " hello kitty "这句话
- 使用 "天天" 可能无法检索到 "今天天气不错"

**** FTS in sqlite3
- create virtual table search_index using fts3(content TEXT, tokenize=porter);
  tokenize 可以为 simple, porter, icu, 但默认情况下 icu tokenizer 功能没有被编译
  到 sqlite3 中
- select * from search_index where content match "token1 token2"
- select * from search_index where content match "tok*"

*** SQLite Optimization FAQ

http://web.utk.edu/~jplyon/sqlite/SQLite_optimization_FAQ.html

* Footnotes

[fn:1] because A is holding a `shared` lock

[fn:2] because B is holding a `reserved` lock

[fn:3] 具体的情况应该取决于: 1. page cache 的大小 2. 生产者(sql 程序)
与消费者(io) 的处理数据的速度的差
